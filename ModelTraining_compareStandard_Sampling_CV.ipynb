{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Introduction**\n",
    "\n",
    "In the real world of machine learning, particularly in fraud detection, disease diagnosis, or anomaly detection, we often face a common challenge: imbalanced datasets. When one class significantly outnumbers the other, our models can become biased, leading to suboptimal performance where the minority class - often the one we're most interested in - gets overlooked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTES:\n",
    "\n",
    "\n",
    "- https://towardsdatascience.com/how-to-build-a-custom-estimator-for-scikit-learn-fddc0cb9e16e/ - paper sample in CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import os\n",
    "from functools import partial\n",
    "# import model libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet('data/credit_card_transactions.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_columns = ['trans_date_trans_time','gender','street','trans_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                          1852394\n",
       "mean     2020-01-20 21:31:46.801827328\n",
       "min                2019-01-01 00:00:18\n",
       "25%      2019-07-23 04:13:43.750000128\n",
       "50%                2020-01-02 01:15:31\n",
       "75%      2020-07-23 12:11:25.249999872\n",
       "max                2020-12-31 23:59:34\n",
       "Name: trans_date_trans_time, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.trans_date_trans_time.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4v/kjjy1y7j1bqbg_ys11l8_wgh0000gn/T/ipykernel_86061/23874701.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ym_stats['ym'] = data.trans_date_trans_time.dt.year.astype(str) + data.trans_date_trans_time.dt.month.astype(str).str.zfill(2)\n",
      "/var/folders/4v/kjjy1y7j1bqbg_ys11l8_wgh0000gn/T/ipykernel_86061/23874701.py:3: FutureWarning: The provided callable <built-in function sum> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  ym_stats.groupby(['ym']).agg({'is_fraud':sum, 'trans_num': 'nunique'})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_fraud</th>\n",
       "      <th>trans_num</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ym</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201901</th>\n",
       "      <td>506</td>\n",
       "      <td>52525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201902</th>\n",
       "      <td>517</td>\n",
       "      <td>49866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201903</th>\n",
       "      <td>494</td>\n",
       "      <td>70939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201904</th>\n",
       "      <td>376</td>\n",
       "      <td>68078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201905</th>\n",
       "      <td>408</td>\n",
       "      <td>72532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201906</th>\n",
       "      <td>354</td>\n",
       "      <td>86064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201907</th>\n",
       "      <td>331</td>\n",
       "      <td>86596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201908</th>\n",
       "      <td>382</td>\n",
       "      <td>87359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201909</th>\n",
       "      <td>418</td>\n",
       "      <td>70652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201910</th>\n",
       "      <td>454</td>\n",
       "      <td>68758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201911</th>\n",
       "      <td>388</td>\n",
       "      <td>70421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201912</th>\n",
       "      <td>592</td>\n",
       "      <td>141060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202001</th>\n",
       "      <td>343</td>\n",
       "      <td>52202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202002</th>\n",
       "      <td>336</td>\n",
       "      <td>47791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202003</th>\n",
       "      <td>444</td>\n",
       "      <td>72850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202004</th>\n",
       "      <td>302</td>\n",
       "      <td>66892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202005</th>\n",
       "      <td>527</td>\n",
       "      <td>74343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202006</th>\n",
       "      <td>467</td>\n",
       "      <td>87805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202007</th>\n",
       "      <td>321</td>\n",
       "      <td>85848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202008</th>\n",
       "      <td>415</td>\n",
       "      <td>88759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202009</th>\n",
       "      <td>340</td>\n",
       "      <td>69533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202010</th>\n",
       "      <td>384</td>\n",
       "      <td>69348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202011</th>\n",
       "      <td>294</td>\n",
       "      <td>72635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202012</th>\n",
       "      <td>258</td>\n",
       "      <td>139538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        is_fraud  trans_num\n",
       "ym                         \n",
       "201901       506      52525\n",
       "201902       517      49866\n",
       "201903       494      70939\n",
       "201904       376      68078\n",
       "201905       408      72532\n",
       "201906       354      86064\n",
       "201907       331      86596\n",
       "201908       382      87359\n",
       "201909       418      70652\n",
       "201910       454      68758\n",
       "201911       388      70421\n",
       "201912       592     141060\n",
       "202001       343      52202\n",
       "202002       336      47791\n",
       "202003       444      72850\n",
       "202004       302      66892\n",
       "202005       527      74343\n",
       "202006       467      87805\n",
       "202007       321      85848\n",
       "202008       415      88759\n",
       "202009       340      69533\n",
       "202010       384      69348\n",
       "202011       294      72635\n",
       "202012       258     139538"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ym_stats = data[['trans_date_trans_time','state','is_fraud','trans_num']]\n",
    "ym_stats['ym'] = data.trans_date_trans_time.dt.year.astype(str) + data.trans_date_trans_time.dt.month.astype(str).str.zfill(2)\n",
    "ym_stats.groupby(['ym']).agg({'is_fraud':sum, 'trans_num': 'nunique'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['trans_date_trans_time', 'merchant', 'category', 'amt', 'gender',\n",
       "       'street', 'city', 'state', 'zip', 'city_pop', 'job', 'trans_num',\n",
       "       'unix_time', 'is_fraud', 'age_at_purchase', 'age_group',\n",
       "       'transaction_day_of_the_week', 'transaction_time_of_the_day',\n",
       "       'transaction_month', 'distance_from_mercant_km'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trans_date_trans_time</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amt</th>\n",
       "      <th>gender</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>job</th>\n",
       "      <th>trans_num</th>\n",
       "      <th>unix_time</th>\n",
       "      <th>is_fraud</th>\n",
       "      <th>age_at_purchase</th>\n",
       "      <th>age_group</th>\n",
       "      <th>transaction_day_of_the_week</th>\n",
       "      <th>transaction_time_of_the_day</th>\n",
       "      <th>transaction_month</th>\n",
       "      <th>distance_from_mercant_km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 00:00:18</td>\n",
       "      <td>fraud_Rippin, Kub and Mann</td>\n",
       "      <td>misc_net</td>\n",
       "      <td>4.97</td>\n",
       "      <td>F</td>\n",
       "      <td>561 Perry Cove</td>\n",
       "      <td>Moravian Falls</td>\n",
       "      <td>NC</td>\n",
       "      <td>28654</td>\n",
       "      <td>3495</td>\n",
       "      <td>Psychologist, counselling</td>\n",
       "      <td>0b242abb623afc578575680df30655b9</td>\n",
       "      <td>1325376018</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>78.773821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 00:00:44</td>\n",
       "      <td>fraud_Heller, Gutmann and Zieme</td>\n",
       "      <td>grocery_pos</td>\n",
       "      <td>107.23</td>\n",
       "      <td>F</td>\n",
       "      <td>43039 Riley Greens Suite 393</td>\n",
       "      <td>Orient</td>\n",
       "      <td>WA</td>\n",
       "      <td>99160</td>\n",
       "      <td>149</td>\n",
       "      <td>Special educational needs teacher</td>\n",
       "      <td>1f76529f8574734946361c461b024d99</td>\n",
       "      <td>1325376044</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.216618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 00:00:51</td>\n",
       "      <td>fraud_Lind-Buckridge</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>220.11</td>\n",
       "      <td>M</td>\n",
       "      <td>594 White Dale Suite 530</td>\n",
       "      <td>Malad City</td>\n",
       "      <td>ID</td>\n",
       "      <td>83252</td>\n",
       "      <td>4154</td>\n",
       "      <td>Nature conservation officer</td>\n",
       "      <td>a1a22d70485983eac12b5b88dad1cf95</td>\n",
       "      <td>1325376051</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>108.102912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 00:01:16</td>\n",
       "      <td>fraud_Kutch, Hermiston and Farrell</td>\n",
       "      <td>gas_transport</td>\n",
       "      <td>45.00</td>\n",
       "      <td>M</td>\n",
       "      <td>9443 Cynthia Court Apt. 038</td>\n",
       "      <td>Boulder</td>\n",
       "      <td>MT</td>\n",
       "      <td>59632</td>\n",
       "      <td>1939</td>\n",
       "      <td>Patent attorney</td>\n",
       "      <td>6b849c168bdad6f867558c3793159a81</td>\n",
       "      <td>1325376076</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>95.685115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 00:03:06</td>\n",
       "      <td>fraud_Keeling-Crist</td>\n",
       "      <td>misc_pos</td>\n",
       "      <td>41.96</td>\n",
       "      <td>M</td>\n",
       "      <td>408 Bradley Rest</td>\n",
       "      <td>Doe Hill</td>\n",
       "      <td>VA</td>\n",
       "      <td>24433</td>\n",
       "      <td>99</td>\n",
       "      <td>Dance movement psychotherapist</td>\n",
       "      <td>a41d7549acf90789359a9aa5346dcb46</td>\n",
       "      <td>1325376186</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>77.702395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  trans_date_trans_time                            merchant       category  \\\n",
       "0   2019-01-01 00:00:18          fraud_Rippin, Kub and Mann       misc_net   \n",
       "1   2019-01-01 00:00:44     fraud_Heller, Gutmann and Zieme    grocery_pos   \n",
       "2   2019-01-01 00:00:51                fraud_Lind-Buckridge  entertainment   \n",
       "3   2019-01-01 00:01:16  fraud_Kutch, Hermiston and Farrell  gas_transport   \n",
       "4   2019-01-01 00:03:06                 fraud_Keeling-Crist       misc_pos   \n",
       "\n",
       "      amt gender                        street            city state    zip  \\\n",
       "0    4.97      F                561 Perry Cove  Moravian Falls    NC  28654   \n",
       "1  107.23      F  43039 Riley Greens Suite 393          Orient    WA  99160   \n",
       "2  220.11      M      594 White Dale Suite 530      Malad City    ID  83252   \n",
       "3   45.00      M   9443 Cynthia Court Apt. 038         Boulder    MT  59632   \n",
       "4   41.96      M              408 Bradley Rest        Doe Hill    VA  24433   \n",
       "\n",
       "   city_pop                                job  \\\n",
       "0      3495          Psychologist, counselling   \n",
       "1       149  Special educational needs teacher   \n",
       "2      4154        Nature conservation officer   \n",
       "3      1939                    Patent attorney   \n",
       "4        99     Dance movement psychotherapist   \n",
       "\n",
       "                          trans_num   unix_time  is_fraud  age_at_purchase  \\\n",
       "0  0b242abb623afc578575680df30655b9  1325376018         0               31   \n",
       "1  1f76529f8574734946361c461b024d99  1325376044         0               41   \n",
       "2  a1a22d70485983eac12b5b88dad1cf95  1325376051         0               57   \n",
       "3  6b849c168bdad6f867558c3793159a81  1325376076         0               52   \n",
       "4  a41d7549acf90789359a9aa5346dcb46  1325376186         0               33   \n",
       "\n",
       "   age_group  transaction_day_of_the_week  transaction_time_of_the_day  \\\n",
       "0        3.0                            1                            1   \n",
       "1        3.0                            1                            1   \n",
       "2        4.0                            1                            1   \n",
       "3        4.0                            1                            1   \n",
       "4        3.0                            1                            1   \n",
       "\n",
       "   transaction_month  distance_from_mercant_km  \n",
       "0                  1                 78.773821  \n",
       "1                  1                 30.216618  \n",
       "2                  1                108.102912  \n",
       "3                  1                 95.685115  \n",
       "4                  1                 77.702395  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare datasets for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset preparation is a critical step for modeling. There are multiple ways of doing it, depending on the type of phenomena that one is modeling.\n",
    "Many fall in misconception that fraud is a timeseries event and treat the dataset accordingly. However, even if it is true that past behavior of a customer/a card lead to fraud or not, we cannot state that in general every previous event is the cause for the following. Therefore, frauds follows a time-like event importance, but it is not a timeseries.\n",
    "\n",
    "This means that previous data do not necessary cause the following behaviours. \n",
    "Fraud is, in fact, a circular event: past patterns can be easily seen in the future, with some different nuances. For these reasons when we are modeling fraud it is important to:\n",
    "- Have a good timeframe in the past\n",
    "- Test model stability both on:\n",
    "    * A validation set sampled from the training population. This serve to test that model is able to generalize btw what he has already seen\n",
    "    * An out of time set (oot) that the model has never seen (in the future wrt training set)\n",
    "\n",
    "\n",
    "Also: [TODO]\n",
    "- risk of data likage due to the fact that fraud labels often comes after a certain amount of period\n",
    "- ?how much back in the past depends on use case and frequency of retraining (balance btw precision in short term and stability.)\n",
    "- INTRO: peaks->policy - underlying behavior->models\n",
    "- sampling in CV to grant not to loose info in sampling \n",
    "- sample only train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract OOT and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting dataframe based on expression \"trans_date_trans_time < '2020-07-01 00:00:00'\".\n",
      "Split dataframe into two dataframes with shapes (1326733, 20) and (525661, 20).\n"
     ]
    }
   ],
   "source": [
    "_expression = \"trans_date_trans_time < '2020-07-01 00:00:00'\"\n",
    "print(f\"Splitting dataframe based on expression {_expression!r}.\")\n",
    "data.index = data.trans_num\n",
    "train = data.query(_expression)\n",
    "oot = data.query(f\"~({_expression})\")\n",
    "print(f\"Split dataframe into two dataframes with shapes {train.shape} and {oot.shape}.\")\n",
    "\n",
    "oot_y = oot.is_fraud\n",
    "oot_X = oot.drop(columns=['is_fraud'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "\n",
    "X = train.drop(columns=['is_fraud'])\n",
    "X.drop(metadata_columns, axis=1, inplace=True)\n",
    "y = train['is_fraud']\n",
    "\n",
    "train_X, holdout_X, train_y, holdout_y = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "train_X.drop(columns=['age_at_purchase'], inplace=True)\n",
    "holdout_X.drop(columns=['age_at_purchase'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define support classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomStratifiedKFold:\n",
    "    \"\"\"_summary_\n",
    "    \"\"\"\n",
    "    def __init__(self, n_splits=5, undersample_func=None, shuffle=True, random_state=42):\n",
    "        self.n_splits = n_splits\n",
    "        self.undersample_func = undersample_func\n",
    "        self.random_state = random_state\n",
    "        self.skf = StratifiedKFold(n_splits=self.n_splits, shuffle=shuffle, random_state=self.random_state)\n",
    "\n",
    "    def split(self, dataframe, y):\n",
    "        folds = []\n",
    "        for train_index, test_index in tqdm(self.skf.split(X=dataframe, y=y), desc=\"Generating K-Folds\", total=self.n_splits):\n",
    "            train_df, y_train = dataframe.iloc[train_index], y.iloc[train_index]\n",
    "            test_df, y_test = dataframe.iloc[test_index], y[test_index]\n",
    "\n",
    "            # Oversample only the training data\n",
    "            if self.undersample_func is not None:\n",
    "                train_df, y_train = self.undersample_func.fit_resample(train_df, y_train)\n",
    "\n",
    "            folds.append(((train_df, y_train), (test_df, y_test)))\n",
    "        return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class MultiColumnEncoder(BaseEstimator):\n",
    "    \"\"\"https://www.geeksforgeeks.org/label-encoding-across-multiple-columns-in-scikit-learn/ \n",
    "\n",
    "    Args:\n",
    "        BaseEstimator (_type_): _description_\n",
    "    \"\"\"\n",
    "    def __init__(self, columns=None):\n",
    "        self.columns = columns\n",
    "        oe = partial(OrdinalEncoder, handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "        self.encoders = defaultdict(oe)\n",
    "\n",
    "    def fit(self, X):\n",
    "        for col in self.columns:\n",
    "            self.encoders[col].fit(X[[col]])\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()  # To avoid modifying the original dataframe\n",
    "        for col in self.columns:\n",
    "            X_copy[col] = self.encoders[col].transform(X_copy[[col]])\n",
    "        return X_copy\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.fit(X).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, auc\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "class EvalPlots():\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def plot_eval_basic(self, y_true, y_score):\n",
    "\n",
    "        '''\n",
    "        y_score = model.predict_proba(X)[:, 1]\n",
    "        '''\n",
    "\n",
    "        precision, recall, thresholds = precision_recall_curve(y_true, y_score)\n",
    "\n",
    "        # The histogram of scores compared to true labels\n",
    "        fig_hist = px.histogram(\n",
    "            x=y_score, color=y_true, nbins=50,\n",
    "            labels=dict(color='True Labels', x='Score')\n",
    "            , histnorm='probability density'\n",
    "        )\n",
    "\n",
    "        fig_hist.show()\n",
    "\n",
    "\n",
    "        # Evaluating model performance on PR curve\n",
    "\n",
    "        fig_thresh = px.area(\n",
    "            x=recall, y=precision,\n",
    "            title=f'Precision-Recall Curve (AUC={auc(recall, precision):.4f})',\n",
    "            labels=dict(x='Recall', y='Precision'),\n",
    "            width=700, height=500\n",
    "        )\n",
    "        fig_thresh.add_shape(\n",
    "            type='line', line=dict(dash='dash'),\n",
    "            x0=0, x1=1, y0=1, y1=0\n",
    "        )\n",
    "        fig_thresh.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
    "        fig_thresh.update_xaxes(constrain='domain')\n",
    "\n",
    "        fig_thresh.show()\n",
    "\n",
    "        return fig_hist, fig_thresh\n",
    "    \n",
    "    \n",
    "    \n",
    "    def plot_eval_pred_dist(self, y_train_true, y_train_pred, y_holdout_true, y_holdout_pred, y_oot_true, y_oot_pred):\n",
    "        fig = make_subplots(rows=3, cols=1, subplot_titles=(\"Train\", \"Holdout\", \"OOT\"))\n",
    "        print('inside plot_eval_pred_dist')\n",
    "\n",
    "        trace0 = px.histogram(\n",
    "                    x=y_train_pred, color=y_train_true, nbins=50,\n",
    "                    histnorm='probability density',\n",
    "                    labels=dict(color='True Labels', x='Score')\n",
    "                )\n",
    "        print(  'trace0')\n",
    "        trace1 = px.histogram(\n",
    "                    x=y_holdout_pred, color=y_holdout_true, nbins=50,\n",
    "                    labels=dict(color='True Labels', x='Score')\n",
    "                    , histnorm='probability density'\n",
    "                )\n",
    "        trace2 = px.histogram(\n",
    "                    x=y_oot_pred, color=y_oot_true, nbins=50,\n",
    "                    labels=dict(color='True Labels', x='Score')\n",
    "                    , histnorm='probability density'\n",
    "                )\n",
    "\n",
    "        # add each trace (or traces) to its specific subplot\n",
    "        pl_nr = 0\n",
    "        for plot_ in [trace0, trace1, trace2]:\n",
    "            pl_nr += 1\n",
    "            for trace in plot_.data:\n",
    "                fig.add_trace(trace, row=pl_nr, col=1)\n",
    "\n",
    "        fig.update_layout(title_text=\"Model Performance\", showlegend=True)\n",
    "        return fig\n",
    "\n",
    "    def plot_eval_pr_auc(self, precision_train, recall_train, precision_holdout, recall_holdout, precision_oot, recall_oot):\n",
    "        # Evaluating model performance on PR curve\n",
    "\n",
    "        tr_title = f'Train (AUC={auc(recall_train, precision_train):.4f})' \n",
    "        ho_title = f'Holdout (AUC={auc(recall_holdout, precision_holdout):.4f})'\n",
    "        oot_title = f'OOT (AUC={auc(recall_oot, precision_oot):.4f})'\n",
    "\n",
    "        fig = make_subplots(rows=1, cols=3, subplot_titles=(tr_title, ho_title, oot_title)) \n",
    "\n",
    "        trace0 = px.area(\n",
    "            x=recall_train, y=precision_train,\n",
    "            title=f'Training (AUC={auc(recall_train, precision_train):.4f})',\n",
    "            labels=dict(x='Recall', y='Precision'),\n",
    "            width=700, height=500\n",
    "        )\n",
    "        trace0.add_shape(\n",
    "            type='line', line=dict(dash='dash'),\n",
    "            x0=0, x1=1, y0=1, y1=0\n",
    "        )\n",
    "        trace0.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
    "        trace0.update_xaxes(constrain='domain')\n",
    "\n",
    "        trace1 = px.area(\n",
    "            x=recall_holdout, y=precision_holdout,\n",
    "            title=f'Holdout (AUC={auc(recall_holdout, precision_holdout):.4f})',\n",
    "            labels=dict(x='Recall', y='Precision'),\n",
    "            width=700, height=500\n",
    "        )\n",
    "        trace1.add_shape(\n",
    "            type='line', line=dict(dash='dash'),\n",
    "            x0=0, x1=1, y0=1, y1=0\n",
    "        )\n",
    "        trace1.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
    "        trace1.update_xaxes(constrain='domain')\n",
    "\n",
    "        trace2 = px.area(\n",
    "            x=recall_oot, y=precision_oot,\n",
    "            title=f'OOT AUC={auc(recall_oot, precision_oot):.4f})',\n",
    "            labels=dict(x='Recall', y='Precision'),\n",
    "            width=700, height=500\n",
    "        )\n",
    "        trace2.add_shape(\n",
    "            type='line', line=dict(dash='dash'),\n",
    "            x0=0, x1=1, y0=1, y1=0\n",
    "        )\n",
    "        trace2.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
    "        trace2.update_xaxes(constrain='domain')\n",
    "\n",
    "        pl_nr = 0\n",
    "        for plot_ in [trace0, trace1, trace2]:\n",
    "            pl_nr += 1\n",
    "            for trace in plot_.data:\n",
    "                fig.add_trace(trace, row=1, col=pl_nr)\n",
    "\n",
    "        fig.update_layout(title_text=\"Model Precision-Recall Curve\", showlegend=True)\n",
    "\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Â Build model performance report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "class ModelPerformanceReport(EvalPlots):\n",
    "    def __init__(self, train_X,train_y, holdout_X,holdout_y,oot_X, oot_y):\n",
    "        self.train_X = train_X\n",
    "        self.train_y = train_y\n",
    "        self.holdout_X = holdout_X\n",
    "        self.holdout_y = holdout_y\n",
    "        self.oot_X = oot_X\n",
    "        self.oot_y = oot_y\n",
    "        super().__init__()\n",
    "\n",
    "    def predictions(self, model):\n",
    "        y_train_pred = model.predict(self.train_X)\n",
    "        y_train_true = self.train_y\n",
    "        y_holdout_pred = model.predict(self.holdout_X)\n",
    "        y_holdout_true = self.holdout_y\n",
    "        y_oot_true = self.oot_y\n",
    "        y_oot_pred = model.predict(self.oot_X[self.train_X.columns])\n",
    "\n",
    "        return y_train_pred, y_train_true, y_holdout_pred, y_holdout_true, y_oot_pred, y_oot_true\n",
    "\n",
    "    def produce_report(self, model): \n",
    "        \n",
    "        y_train_pred, y_train_true, y_holdout_pred, y_holdout_true, y_oot_pred, y_oot_true = self.predictions(model)\n",
    "\n",
    "        # confusion_matrix(y_train_true, y_train_pred)\n",
    "\n",
    "\n",
    "        results_df = pd.DataFrame()\n",
    "        results_df['train'] = [accuracy_score(y_train_true, y_train_pred), precision_score(y_train_true, y_train_pred), recall_score(y_train_true, y_train_pred), f1_score(y_train_true, y_train_pred)]\n",
    "        results_df['holdout'] = [accuracy_score(y_holdout_true, y_holdout_pred), precision_score(y_holdout_true, y_holdout_pred), recall_score(y_holdout_true, y_holdout_pred), f1_score(y_holdout_true, y_holdout_pred)]   \n",
    "        results_df['oot'] = [accuracy_score(y_oot_true, y_oot_pred), precision_score(y_oot_true, y_oot_pred), recall_score(y_oot_true, y_oot_pred), f1_score(y_oot_true, y_oot_pred)]\n",
    "        results_df.index = ['accuracy', 'precision', 'recall', 'f1']\n",
    "        return results_df\n",
    "    \n",
    "\n",
    "    def proba_predictions(self, model):\n",
    "        y_train_pred = model.predict_proba(self.train_X)[:, 1]\n",
    "        y_train_true = self.train_y\n",
    "        y_holdout_pred = model.predict_proba(holdout_X)[:, 1]\n",
    "        y_holdout_true = self.holdout_y\n",
    "        y_oot_true = self.oot_y\n",
    "        y_oot_pred = model.predict_proba(self.oot_X[self.train_X.columns])[:, 1]\n",
    "\n",
    "        return y_train_pred, y_train_true, y_holdout_pred, y_holdout_true, y_oot_true, y_oot_pred\n",
    "    \n",
    "    def produce_proba_report(self, model):\n",
    "        y_train_true, y_train_pred, y_holdout_true, y_holdout_pred, y_oot_true, y_oot_pred = self.proba_predictions(model)\n",
    "        return self.plot_eval_pred_dist(y_train_true, y_train_pred, y_holdout_true, y_holdout_pred, y_oot_true, y_oot_pred)\n",
    "\n",
    "    def precision_recall_calc(self, y_train_true, y_train_pred, y_holdout_true, y_holdout_pred, y_oot_true, y_oot_pred):\n",
    "        precision_train, recall_train, _ = precision_recall_curve(y_train_true, y_train_pred)\n",
    "        precision_holdout, recall_holdout, _ = precision_recall_curve(y_holdout_true, y_holdout_pred)\n",
    "        precision_oot, recall_oot, _ = precision_recall_curve(y_oot_true, y_oot_pred)\n",
    "        return precision_train, recall_train, precision_holdout, recall_holdout, precision_oot, recall_oot\n",
    "\n",
    "    def produce_pr_auc_report(self, model):\n",
    "        y_train_pred, y_train_true, y_holdout_pred, y_holdout_true, y_oot_true, y_oot_pred = self.proba_predictions(model)\n",
    "        precision_train, recall_train, precision_holdout, recall_holdout, precision_oot, recall_oot = self.precision_recall_calc(y_train_true, y_train_pred, y_holdout_true, y_holdout_pred, y_oot_true, y_oot_pred)\n",
    "        return self.plot_eval_pr_auc(precision_train, recall_train, precision_holdout, recall_holdout, precision_oot, recall_oot) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trasform dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = X.select_dtypes(include=['object']).columns.tolist()\n",
    "encoder = MultiColumnEncoder(categorical_columns)\n",
    "train_X = encoder.fit_transform(train_X)\n",
    "holdout_X = encoder.transform(holdout_X)\n",
    "oot_X = encoder.transform(oot_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_class = ModelPerformanceReport(train_X,train_y,holdout_X,holdout_y,oot_X,oot_y)\n",
    "eval_plots = EvalPlots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard run\n",
    "no balancing\n",
    "no tuning\n",
    "\n",
    "\n",
    "Add description\n",
    "Observations on overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6157, number of negative: 1055229\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003153 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2115\n",
      "[LightGBM] [Info] Number of data points in the train set: 1061386, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.005801 -> initscore=-5.143923\n",
      "[LightGBM] [Info] Start training from score -5.143923\n"
     ]
    }
   ],
   "source": [
    "score_standard_model = LGBMClassifier(objective='binary').fit(train_X, train_y)#, eval_metric='average_precision') #default logloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_standard_model.n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>holdout</th>\n",
       "      <th>oot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.997707</td>\n",
       "      <td>0.997034</td>\n",
       "      <td>0.995655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.833782</td>\n",
       "      <td>0.743860</td>\n",
       "      <td>0.452146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.755238</td>\n",
       "      <td>0.715250</td>\n",
       "      <td>0.638668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.792569</td>\n",
       "      <td>0.729274</td>\n",
       "      <td>0.529460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              train   holdout       oot\n",
       "accuracy   0.997707  0.997034  0.995655\n",
       "precision  0.833782  0.743860  0.452146\n",
       "recall     0.755238  0.715250  0.638668\n",
       "f1         0.792569  0.729274  0.529460"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_class.produce_report(score_standard_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred, y_train_true, y_holdout_pred, y_holdout_true, y_oot_true, y_oot_pred = report_class.predictions(score_standard_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['merchant', 'category', 'amt', 'city', 'state', 'zip', 'city_pop',\n",
       "       'job', 'unix_time', 'age_group', 'transaction_day_of_the_week',\n",
       "       'transaction_time_of_the_day', 'transaction_month',\n",
       "       'distance_from_mercant_km'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amt</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>job</th>\n",
       "      <th>unix_time</th>\n",
       "      <th>age_group</th>\n",
       "      <th>transaction_day_of_the_week</th>\n",
       "      <th>transaction_time_of_the_day</th>\n",
       "      <th>transaction_month</th>\n",
       "      <th>distance_from_mercant_km</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trans_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42120e2054d1397b85b0e3a6334b42cf</th>\n",
       "      <td>362.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>22.80</td>\n",
       "      <td>494.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>17051</td>\n",
       "      <td>4653</td>\n",
       "      <td>313.0</td>\n",
       "      <td>1361916693</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>101.462880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9e1feddcb44cbd60e084a121d1ce6797</th>\n",
       "      <td>210.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.51</td>\n",
       "      <td>696.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>18246</td>\n",
       "      <td>143</td>\n",
       "      <td>217.0</td>\n",
       "      <td>1360688735</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>60.229398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9233b4c947e092f5070af77d777b7b39</th>\n",
       "      <td>598.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>33.72</td>\n",
       "      <td>101.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4616</td>\n",
       "      <td>824</td>\n",
       "      <td>276.0</td>\n",
       "      <td>1337996045</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>60.185865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  merchant  category    amt   city  state  \\\n",
       "trans_num                                                                   \n",
       "42120e2054d1397b85b0e3a6334b42cf     362.0       6.0  22.80  494.0   38.0   \n",
       "9e1feddcb44cbd60e084a121d1ce6797     210.0       0.0  79.51  696.0   38.0   \n",
       "9233b4c947e092f5070af77d777b7b39     598.0       9.0  33.72  101.0   21.0   \n",
       "\n",
       "                                    zip  city_pop    job   unix_time  \\\n",
       "trans_num                                                              \n",
       "42120e2054d1397b85b0e3a6334b42cf  17051      4653  313.0  1361916693   \n",
       "9e1feddcb44cbd60e084a121d1ce6797  18246       143  217.0  1360688735   \n",
       "9233b4c947e092f5070af77d777b7b39   4616       824  276.0  1337996045   \n",
       "\n",
       "                                  age_group  transaction_day_of_the_week  \\\n",
       "trans_num                                                                  \n",
       "42120e2054d1397b85b0e3a6334b42cf        2.0                            2   \n",
       "9e1feddcb44cbd60e084a121d1ce6797        3.0                            2   \n",
       "9233b4c947e092f5070af77d777b7b39        3.0                            6   \n",
       "\n",
       "                                  transaction_time_of_the_day  \\\n",
       "trans_num                                                       \n",
       "42120e2054d1397b85b0e3a6334b42cf                            5   \n",
       "9e1feddcb44cbd60e084a121d1ce6797                            3   \n",
       "9233b4c947e092f5070af77d777b7b39                            1   \n",
       "\n",
       "                                  transaction_month  distance_from_mercant_km  \n",
       "trans_num                                                                      \n",
       "42120e2054d1397b85b0e3a6334b42cf                  2                101.462880  \n",
       "9e1feddcb44cbd60e084a121d1ce6797                  2                 60.229398  \n",
       "9233b4c947e092f5070af77d777b7b39                  5                 60.185865  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_fraud\n",
       "0    523649\n",
       "1      2012\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_oot_pred).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    522819\n",
       "1      2842\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_oot_true).value_counts( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005220094319342694"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2744/(2744+522917)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train_true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m report_class\u001b[38;5;241m.\u001b[39mplot_eval_pred_dist(\u001b[43my_train_true\u001b[49m, y_train_pred, y_holdout_true, y_holdout_pred, y_oot_true, y_oot_pred)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_train_true' is not defined"
     ]
    }
   ],
   "source": [
    "report_class.plot_eval_pred_dist(y_train_true, y_train_pred, y_holdout_true, y_holdout_pred, y_oot_true, y_oot_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_class.produce_pr_auc_report(score_standard_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_train = score_standard_model.predict_proba(train_X)[:, 1]\n",
    "fig_hist, fig_thresh = eval_plots.plot_eval_basic(y_true = train_y, y_score=y_predict_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add balancing\n",
    "Why it is needed, what is solves for\n",
    "\n",
    "*Note:\n",
    "When trying to add SMOTE to my pipeline in my project, I hit an error. The issue is that sklearnâs pipeline will try to oversample the training and validation sets, which is not what you want to do with SMOTE. To fix this, imblearn has a pipeline that is built on top of sklearnâs pipeline, meaning it functions almost exactly the same way. However, when you call the predict( ) method, the imblearn pipeline will skip the sampling step, solving this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "undersample_pipe = Pipeline([('sampling', RandomUnderSampler(sampling_strategy=0.2, random_state=42)) \n",
    "                             , ('class', LGBMClassifier(objective='binary'))])\n",
    "score_balanced_model = undersample_pipe.fit(train_X, train_y\n",
    "                                            , class__eval_metric='average_precision'\n",
    "                                            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_balanced_model['class'].n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_class.produce_report(score_balanced_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred, y_train_true, y_holdout_pred, y_holdout_true, y_oot_true, y_oot_pred = report_class.predictions(score_balanced_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_train_pred).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_class.produce_pr_auc_report(score_balanced_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "        #'encode__columns': [categorical_columns],\n",
    "        'class__n_estimators': [20, 50, 200, 500],\n",
    "        \"class__objective\": [\"binary\"],\n",
    "        \"class__early_stopping_round\": [10],\n",
    "        \"class__num_leaves\": [5, 10, 80, 100],\n",
    "        \"class__min_data_in_leaf\": [10, 50, 100, 200],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "\n",
    "#, ('encode',MultiColumnLabelEncoder())\n",
    "undersample_pipe = Pipeline([('sampling', RandomUnderSampler(sampling_strategy=0.1, random_state=42)) \n",
    "                             , ('class', LGBMClassifier(objective='binary'))])\n",
    "\n",
    "score_balanced_parameter_model = GridSearchCV(undersample_pipe, param_grid=hyperparameters, cv=3, scoring='average_precision')\n",
    "\n",
    "score_balanced_parameter_model.fit(train_X, train_y, class__eval_set=(holdout_X, holdout_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_class.produce_report(score_balanced_parameter_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_class.produce_pr_auc_report(score_balanced_parameter_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test BalancedBaggingClassifier\n",
    "https://medium.com/@nageshmashette32/balanced-bagging-classifier-bagging-for-imbalanced-classification-dfba66c44c14\n",
    "https://imbalanced-learn.org/stable/references/generated/imblearn.ensemble.BalancedBaggingClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "categorical_columns = X.select_dtypes(include=['object']).columns.tolist()\n",
    "hyperparameters_bbc = {\n",
    "        'estimator__n_estimators': [20, 50, 100, 200, 500],\n",
    "        \"estimator__objective\": [\"binary\"],\n",
    "        \"estimator__early_stopping_round\": [10],\n",
    "        \"estimator__num_leaves\": [5, 10, 30, 50, 80, 100],\n",
    "        \"estimator__min_data_in_leaf\": [10, 20, 30, 40, 50, 80, 100, 200],\n",
    "        \"estimator__use_first_metric\": [True],\n",
    "        'n_estimators': [3, 4, 10],\n",
    "        'sampling_strategy': [0.10, 0.15, 0.2, 0.25, 0.3, 0.4]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''bbc = BalancedBaggingClassifier(base_estimator=LGBMClassifier\n",
    "                                , sampling_strategy=0.2, \n",
    "                                random_state=42\n",
    "                                , n_estimators=10,\n",
    "                                oob_score=True, warm_start=True, n_jobs=-1)\n",
    "bbc.fit(train_X, train_y)'''\n",
    "scores_bcc = GridSearchCV(BalancedBaggingClassifier(estimator=LGBMClassifier(),\n",
    "                                random_state=42,\n",
    "                                oob_score=True, warm_start=True, n_jobs=-1)\n",
    "                                , param_grid=hyperparameters_bbc, cv=3, scoring='average_precision'\n",
    "                                )\n",
    "\n",
    "scores_bcc.fit(train_X, train_y, eval_set=(holdout_X, holdout_y))\n",
    "#scores['test_roc_auc'].mean(), \n",
    "scores_bcc['test_average_precision'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare models\n",
    "\n",
    "Show how model stability changes between the 3 model versions and explain why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models results\n",
    "\n",
    "# Generate reports for standard model\n",
    "standard_report = report_class.produce_report(score_standard_model)\n",
    "standard_pr_auc_report = report_class.produce_pr_auc_report(score_standard_model)\n",
    "\n",
    "# Generate reports for balanced model\n",
    "balanced_report = report_class.produce_report(score_balanced_model)\n",
    "balanced_pr_auc_report = report_class.produce_pr_auc_report(score_balanced_model)\n",
    "\n",
    "# Generate reports for balanced parameter tuned model\n",
    "balanced_param_report = report_class.produce_report(score_balanced_parameter_model)\n",
    "balanced_param_pr_auc_report = report_class.produce_pr_auc_report(score_balanced_parameter_model)\n",
    "\n",
    "# Combine reports into a single DataFrame for comparison\n",
    "comparison_df = pd.concat([standard_report.add_suffix('_standard'), balanced_report.add_suffix('_balanced'), balanced_param_report.add_suffix('_tuned')], axis=1)\n",
    "#comparison_df.columns = ['Standard Model', 'Balanced Model', 'Balanced Parameter Tuned Model']\n",
    "\n",
    "# Display the comparison DataFrame\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df =standard_report\n",
    "plot_df['model'] = 'standard'\n",
    "plot_df = pd.concat([plot_df,balanced_report])\n",
    "plot_df['model'] = plot_df.model.fillna('balanced')\n",
    "plot_df = pd.concat([plot_df,balanced_param_report])\n",
    "plot_df['model'] = plot_df.model.fillna('balanced_param')\n",
    "plot_df.reset_index(inplace=True, names='metric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.melt(plot_df, id_vars=['metric', 'model'], value_vars=['train', 'holdout', 'oot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dash import Dash, dcc, html, Input, Output\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model, tree, neighbors\n",
    "from sklearn import metrics, datasets\n",
    "import plotly.express as px\n",
    "\n",
    "app = Dash(__name__)\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.H4(\"Analysis of the ML model's results using scoring metrics\"),\n",
    "    html.P(\"Select metric:\"),\n",
    "    dcc.Dropdown(\n",
    "        id='dropdown',\n",
    "        options=['accuracy', 'precision', 'recall', 'f1'],\n",
    "        value='precision',\n",
    "        clearable=False\n",
    "    ),\n",
    "    dcc.Graph(id=\"graph\"),\n",
    "])\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"graph\", \"figure\"), \n",
    "    Input('dropdown', \"value\"))\n",
    "\n",
    "def train_and_display(metric):\n",
    "\n",
    "\n",
    "    fig = px.line(plot_df[plot_df.metric==metric], y='value', x='variable', color='model', markers=True)\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "app.run_server(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dash import Dash, dcc, html, Input, Output\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model, tree, neighbors\n",
    "from sklearn import metrics, datasets\n",
    "import plotly.express as px\n",
    "\n",
    "app = Dash(__name__)\n",
    "MODELS = {'standard': score_standard_model, 'balanced': score_balanced_model, 'balanced_param': score_balanced_parameter_model}\n",
    "app.layout = html.Div([\n",
    "    html.H4(\"Analysis of the ML model's results using scoring metrics\"),\n",
    "    html.P(\"Select metric:\"),\n",
    "    dcc.Dropdown(\n",
    "        id='dropdown',\n",
    "        options= ['standard', 'balanced', 'balanced_param'],\n",
    "        value='balanced_param',\n",
    "        clearable=False\n",
    "    ),\n",
    "    dcc.Graph(id=\"graph\"),\n",
    "])\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"graph\", \"figure\"), \n",
    "    Input('dropdown', \"value\"))\n",
    "\n",
    "def train_and_display(model):\n",
    "\n",
    "    return report_class.produce_pr_auc_report(MODELS[model])\n",
    "\n",
    "\n",
    "app.run_server(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
